{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Gem_of_data_science_TODO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamabdi/gem_of_data_science/blob/main/Gem_of_data_science_TODO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy7BV_Q6MGGH"
      },
      "source": [
        "# What is classification?\n",
        "Basic task in Computer Vision\n",
        "\n",
        "## Training: \n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*oB3S5yHHhvougJkPXuc8og.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inybqIrxQ4py"
      },
      "source": [
        "# Why it is difficult?!\n",
        "\n",
        "1.   Semantic Gap - Did machines see the same way we do? Nope\n",
        "2.   Illumination\n",
        "3.   View point\n",
        "4.   Deformation\n",
        "5.   Occlusion\n",
        "6.   Background Clutter\n",
        "7.   Intraclass variation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8cr0SBxUQgU"
      },
      "source": [
        "# Now how we can implement that?\n",
        "#### What you'll learn\n",
        "\n",
        "1. What is a neural network and how to train it\n",
        "2. How to build 1-layer FC neural network using PyTorch\n",
        "3. How to add more layers\n",
        "4. How to pick hyperparams for your model\n",
        "5. How to build convolutional networks and train them\n",
        "\n",
        "How about overfitting, dropout, learning rate decay? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QByvanOV1Lam"
      },
      "source": [
        "# Pytorch in Colab \n",
        "Pytorch is an awesome Deep Learning Framework from Facebook [link text](http://pytorch.org) \\\\\n",
        "Colab - Google actually gives you a free GPU for a limited time (12 hours) and you can run your code in Jupyter Notebook in the brower ))) \\\\\n",
        "Isn't that GREAAAAT ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKkkGQps1TYm"
      },
      "source": [
        "# Import all necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dUrEmvO1YUn"
      },
      "source": [
        "import PIL.Image as image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import PyTorch packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as model\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oBNmlEL7brj",
        "outputId": "6a0ab24b-818a-4672-d9e8-30d54f803870"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov  6 06:10:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4-Ru4Q91hF8"
      },
      "source": [
        "# Load data\n",
        "For this experiments we will be using MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-qJ7liy1qJQ"
      },
      "source": [
        "root = './data'\n",
        "batch_size = 64\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
        "# The output of torchvision datasets are images with values in range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "\n",
        "'''#To load data you need 3 componets \n",
        "1. Dataset\n",
        "2. Data Preprocessing \n",
        "3. Dataloader\n",
        "'''\n",
        "\n",
        "# Data Preprocessing \n",
        "transform = transforms.Compose([\n",
        "                       # The output of torchvision datasets are images with values in range [0, 1].\n",
        "                       # We transform them to Tensors with values in range [-1, 1]\n",
        "                       transforms.ToTensor(), \n",
        "                       transforms.Normalize((0.1307,), (0.3081,))]) # for better learning we need to substract mean and devide by std\n",
        "                      # can add more data preprocessing techniques: scaling, crop, randomly change the brightness, contrast, saturation and hue of an image, etc...\n",
        "# Create dataset  \n",
        "train_dataset = datasets.MNIST(root, train=True, download=True, transform=transform)\n",
        "\n",
        "# Dataloader \n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,  batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "# TODO \n",
        "# Write transform, dataset and dataloader for test data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3G9K96F3nvQ"
      },
      "source": [
        "# Look at your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "yrdtxfcC3qNZ",
        "outputId": "7cf141eb-3565-4316-fcf3-47a56309c5af"
      },
      "source": [
        "def imshow(inp, name, title=None):\n",
        "    import pylab\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    #inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = inp.squeeze().numpy()\n",
        "    mean = np.array([0.1307])\n",
        "    std = np.array([0.3081])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp,  cmap=pylab.gray())\n",
        "    result = image.fromarray((inp * 255).astype(np.uint8))\n",
        "  #  result.save(name)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    \n",
        "for batch_idx, (data, target) in enumerate(train_loader):\n",
        "  id = 1 # id image from the data batch \n",
        "  sample = data[id] # change number to any id in the batch (0, batch_size-1)\n",
        "  print(sample.shape) # size of the images \n",
        "  imshow(sample, 'sample', target[id].numpy())\n",
        "  break\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yhDUAoV5Fpz"
      },
      "source": [
        "# Create a model for training\n",
        "New model class is defined as a new nn.Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBGBK5HM9PzK"
      },
      "source": [
        "## FC\n",
        "\n",
        "Let's start with a simple Fully Connected Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-At5xLqB2yu"
      },
      "source": [
        "![alt text](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/e218e6eee9da4e.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBA_KzMUAzTK"
      },
      "source": [
        "# Create 1-layer FC model\n",
        "class Simple_FC(nn.Module):\n",
        "    def __init__(self, input_size=784, num_classes=10):\n",
        "        super(Simple_FC, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        out = self.fc1(x) # weighted sum of input and network weights -> Wx+b, b - bias\n",
        "        return out # return logits - activations before softmax layer "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLkOFJUHFjTe"
      },
      "source": [
        "![alt text](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/fba0638cc213a29.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6alIPVw3uZe0"
      },
      "source": [
        "# Create model with 5 layers \n",
        "class Deep_FC(nn.Module):\n",
        "    def __init__(self, input_size=784, num_classes=10):\n",
        "        super(Deep_FC, self).__init__()\n",
        "        # TODO \n",
        "        # create 5 layer network \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        # TODO\n",
        "        # write how 5 layer network processes the input data \n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buI_vFTP9eoC"
      },
      "source": [
        "## CNN\n",
        "Now let's see how we get even more from the network with a better architecture (CNN) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htjxOKrNLwcy"
      },
      "source": [
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*oB3S5yHHhvougJkPXuc8og.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu1DYw-n5N6f"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.bn1 = nn.BatchNorm2d(10)\n",
        "        self.bn2 = nn.BatchNorm2d(20)\n",
        "        self.bn3 = nn.BatchNorm1d(50)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        # TODO \n",
        "        # write 2 fully connected layers \n",
        "\n",
        "        # TODO 2\n",
        "        # change activation function to Sigmoid and train model \n",
        "      \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.activation(F.max_pool2d(self.bn1(self.conv1(x)), 2))\n",
        "        x = self.activation(F.max_pool2d(self.bn2(self.conv2(x)), 2))\n",
        "\n",
        "        x = x.view(-1, 16*20)\n",
        "        \n",
        "        # TODO \n",
        "        # write how FC layers process output of convolutional layers\n",
        "        \n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JqcoNmh95Uo"
      },
      "source": [
        "## Pick model for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbBOhJv46Jfy"
      },
      "source": [
        "model = Simple_FC()\n",
        "# model = Deep_FC()\n",
        "# model = CNN()\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7k6XE5J6M9v"
      },
      "source": [
        "# Define a Loss Function(Criterion) and an Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkFyyXAK6MfL"
      },
      "source": [
        "lr = 0.01 \n",
        "momentum = 0.9\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0w-4uFa7HU8"
      },
      "source": [
        "log_interval = 100\n",
        "def train(epoch):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # move data to GPU for faster computation\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # remove previous computations from Optimizer\n",
        "        optimizer.zero_grad() \n",
        "        # get predictions from the model\n",
        "        output = model(data) \n",
        "        # compute error\n",
        "        loss = criterion(output, target)\n",
        "        # calculate how much each layer should be modified\n",
        "        loss.backward() \n",
        "        # update model parameters\n",
        "        optimizer.step() \n",
        "            \n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.00f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
        "            \n",
        "            # Compute accuracy\n",
        "            _, argmax = torch.max(output, 1)\n",
        "            accuracy = (target == argmax.squeeze()).float().mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLYPUPqB8qdm"
      },
      "source": [
        "# Check the model accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxsnSEvA8vsJ"
      },
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        # TODO \n",
        "        # move data to GPU for faster computation\n",
        "        \n",
        "        # TODO \n",
        "        # get predictions from the model\n",
        "       \n",
        "        # compute accumulative error over all test samples \n",
        "        test_loss += criterion(output, target).data.item()\n",
        "        # get predictions\n",
        "        pred = output.data.max(1)[1] \n",
        "        # count how many images were correctly classified\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "\n",
        "    test_loss = test_loss\n",
        "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYrKRLW37k4t"
      },
      "source": [
        "# Let's Finally Train your Created Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rcTY3Jy7aX5",
        "outputId": "880d7eb9-5cb1-437d-eaf0-79b1e536e683"
      },
      "source": [
        "epochs = 1\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.316117\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.509516\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.306459\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.319104\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.199463\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.355488\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.157422\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.256930\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.522515\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.424172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4TsRr9A86KB",
        "outputId": "a0847a0b-1958-4a77-8244-5d8907c6bca1"
      },
      "source": [
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3030, Accuracy: 9159/10000 (91.59%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E6vI1aPDwk6"
      },
      "source": [
        "## But real life is not perfect. So your real function will probably look like that. Still  good \n",
        "![alt text](https://cdn-images-1.medium.com/max/1200/1*msObu3xbQzSnKvtCW2z6YQ.png)"
      ]
    }
  ]
}